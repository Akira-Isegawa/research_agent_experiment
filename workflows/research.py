"""ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼."""
from typing import Tuple, Optional
from agents import Runner
from agents.exceptions import ModelBehaviorError
import json


# LLMå‡ºåŠ›ãŒãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã§åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸå ´åˆã®ãƒªãƒˆãƒ©ã‚¤ä¸Šé™
MAX_PARSE_RETRIES = 2

from agent_definitions import (
    create_simple_searcher_agent,
    create_search_planner_agent,
    create_researcher_agent,
    create_evaluator_agent,
    create_comparison_analyzer_agent,
    create_fact_checker_agent,
)
from models.schemas import (
    SimpleSearchOutput,
    SearchPlanOutput,
    ResearchResultOutput,
    EvaluationOutput,
    ComparisonReportOutput,
    FactCheckResultOutput,
    Finding,
    Evidence,
)


async def _run_with_retry(
    agent,
    prompt: str,
    output_type,
    agent_name: str = "Agent",
    max_retries: int = MAX_PARSE_RETRIES,
    verbose: bool = True,
):
    """
    Runner.runã‚’å®Ÿè¡Œã—ã€ModelBehaviorErrorç™ºç”Ÿæ™‚ã«ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã€‚
    
    LLMãŒãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã§å‡ºåŠ›ã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ã¨ã€JSONãŒé€”ä¸­ã§é€”åˆ‡ã‚Œã¦
    ModelBehaviorError (Invalid JSON) ãŒç™ºç”Ÿã™ã‚‹ã€‚
    ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯å‡ºåŠ›é‡ã‚’æ¸›ã‚‰ã™ã‚ˆã†è¿½åŠ æŒ‡ç¤ºã‚’ä»˜åŠ ã™ã‚‹ã€‚
    
    Args:
        agent: å®Ÿè¡Œã™ã‚‹Agent
        prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        output_type: å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã‚¯ãƒ©ã‚¹
        agent_name: ãƒ­ã‚°è¡¨ç¤ºç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        verbose: ãƒ­ã‚°è¡¨ç¤º
    
    Returns:
        ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ã®å‡ºåŠ›ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    
    Raises:
        ModelBehaviorError: ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¦ã‚‚å¤±æ•—ã—ãŸå ´åˆ
    """
    last_error = None
    
    for attempt in range(1 + max_retries):
        try:
            if attempt == 0:
                current_prompt = prompt
            else:
                # ãƒªãƒˆãƒ©ã‚¤æ™‚: å‡ºåŠ›é‡ã‚’å‰Šæ¸›ã™ã‚‹è¿½åŠ æŒ‡ç¤º
                current_prompt = prompt + f"""

ã€âš ï¸ ãƒªãƒˆãƒ©ã‚¤ {attempt}/{max_retries} - å‡ºåŠ›é‡å‰Šæ¸›æŒ‡ç¤ºã€‘
å‰å›ã®å‡ºåŠ›ãŒãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã§åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã€JSONãŒå£Šã‚Œã¾ã—ãŸã€‚
ä»¥ä¸‹ã‚’å³å®ˆã—ã€å¿…ãšå®Œå…¨ãªJSONã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:
- findings ã¯æœ€å¤§ 8 ä»¶ã«åˆ¶é™ã™ã‚‹ï¼ˆé‡è¦ãªã‚‚ã®ã ã‘å³é¸ï¼‰
- evidence ã¯æœ€å¤§ 5 ä»¶ã«åˆ¶é™ã™ã‚‹ï¼ˆæœ€ã‚‚ä¿¡é ¼æ€§ã®é«˜ã„ã‚‚ã®ï¼‰
- summary ã¯ 200 å­—ä»¥å†…ã«ã™ã‚‹
- research_depth_analysis, interconnections ã¯ç°¡æ½”ã«ï¼ˆå„ 100 å­—ä»¥å†…ï¼‰
- plan_used ã¯ objective ã®ã¿è¨˜è¼‰ã—ä»–ã¯çœç•¥å¯èƒ½
- å®Œå…¨ãªJSONæ§‹é€ ï¼ˆã™ã¹ã¦ã®æ‹¬å¼§ãŒé–‰ã˜ã¦ã„ã‚‹ï¼‰ã‚’å„ªå…ˆã™ã‚‹ã“ã¨
"""
            
            result = await Runner.run(agent, current_prompt)
            output = result.final_output_as(output_type)
            
            if attempt > 0 and verbose:
                print(f"   âœ… ãƒªãƒˆãƒ©ã‚¤{attempt}å›ç›®ã§{agent_name}ã®å‡ºåŠ›ãƒ‘ãƒ¼ã‚¹ã«æˆåŠŸ")
            
            return output
            
        except ModelBehaviorError as e:
            last_error = e
            if verbose:
                if attempt < max_retries:
                    print(f"   âš ï¸  {agent_name}ã®å‡ºåŠ›JSONãŒä¸æ­£ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ‡ã‚Šè©°ã‚ï¼‰ã€‚ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}...")
                else:
                    print(f"   âŒ {agent_name}ã®å‡ºåŠ›JSONãŒ{max_retries + 1}å›é€£ç¶šã§ä¸æ­£ã€‚")
    
    raise last_error


async def run_simple_research(
    theme: str,
    verbose: bool = True,
) -> SimpleSearchOutput:
    """
    ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºAï¼‰.
    
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€Webæ¤œç´¢ã‚’ç”¨ã„ã¦1å›ã®åŒ…æ‹¬çš„ãªæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€
    ä¸»è¦ãªç™ºè¦‹äº‹é …ã¨æ ¹æ‹ æƒ…å ±ã‚’è¿”ã™ã€‚
    
    Args:
        theme: èª¿æŸ»ãƒ†ãƒ¼ãƒ
        verbose: é€²æ—ã‚’è¡¨ç¤ºã™ã‚‹ã‹
    
    Returns:
        SimpleSearchOutput: ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢çµæœ
    """
    if verbose:
        print("=" * 80)
        print("ğŸ” ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºAï¼‰ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 80)
        print(f"ãƒ†ãƒ¼ãƒ: {theme}")
        print()
    
    # ç°¡æ˜“æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    searcher = create_simple_searcher_agent()
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹æˆ
    search_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€åŒ…æ‹¬çš„ã§å¤šé¢çš„ãªãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ:
{theme}

è¦ä»¶:
- è¤‡æ•°ã®ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹
- å¸‚å ´ã€æŠ€è¡“ã€ãƒ“ã‚¸ãƒã‚¹ã€äº‹ä¾‹ãªã©ã€å¤šè§’çš„ãªé ˜åŸŸã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹
- 10-20å€‹ã®ä¸»è¦ãªç™ºè¦‹äº‹é …ã‚’æŠ½å‡ºã™ã‚‹
- ã™ã¹ã¦ã®ç™ºè¦‹äº‹é …ã«æ ¹æ‹ æƒ…å ±ï¼ˆURLã€å‡ºæ‰€ï¼‰ã‚’è¨˜éŒ²ã™ã‚‹
- 300-500å­—ã®ç·æ‹¬ã‚’ä½œæˆã™ã‚‹
"""
    
    # ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢ã‚’å®Ÿè¡Œ
    if verbose:
        print("ğŸ”„ Webæ¤œç´¢ã‚’å®Ÿè¡Œä¸­...")
    
    simple_output = await _run_with_retry(
        searcher, search_prompt, SimpleSearchOutput,
        agent_name="SimpleSearcher", verbose=verbose,
    )
    
    if verbose:
        print("âœ… ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"   ç™ºè¦‹äº‹é …æ•°: {len(simple_output.findings)}")
        print(f"   æ ¹æ‹ æƒ…å ±æ•°: {len(simple_output.evidence)}")
        print()
    
    return simple_output


async def run_agentic_research(
    theme: str,
    max_iterations: int = 5,
    verbose: bool = True,
) -> Tuple[SearchPlanOutput, ResearchResultOutput, list]:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºBï¼‰.
    
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œï¼š
    1. åˆæœŸèª¿æŸ»è¨ˆç”»ç«‹æ¡ˆ
    2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è¨ˆç”»ç¢ºèªãƒ»ä¿®æ­£å—ä»˜
    3. èª¿æŸ»å®Ÿè¡Œ â†’ è©•ä¾¡ â†’ ä¿®æ­£ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’ max_iterations å›å®Ÿè¡Œ
    
    Args:
        theme: èª¿æŸ»ãƒ†ãƒ¼ãƒ
        max_iterations: æœ€å¤§åå¾©å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
        verbose: é€²æ—ã‚’è¡¨ç¤ºã™ã‚‹ã‹
    
    Returns:
        Tuple containing:
            - SearchPlanOutput: æœ€çµ‚çš„ãªèª¿æŸ»è¨ˆç”»
            - ResearchResultOutput: æœ€çµ‚çš„ãªèª¿æŸ»çµæœï¼ˆFCé€šéãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
            - List of EvaluationOutput: å„åå¾©ã§ã®è©•ä¾¡çµæœ
            - List of dict: ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å±¥æ­´
            - List of dict: å„åå¾©ã®researcherç”Ÿçµæœï¼ˆURLæœªå¤‰æ›´ã€æ¤œè¨¼ç”¨ä¿å­˜ï¼‰
    """
    if verbose:
        print("=" * 80)
        print("ğŸ§  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºBï¼‰ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 80)
        print(f"ãƒ†ãƒ¼ãƒ: {theme}")
        print(f"æœ€å¤§åå¾©å›æ•°: {max_iterations}")
        print()
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    planner = create_search_planner_agent()
    researcher = create_researcher_agent()
    evaluator = create_evaluator_agent()
    
    # åå¾©1: åˆæœŸèª¿æŸ»è¨ˆç”»ã‚’ç«‹æ¡ˆ
    if verbose:
        print("â”€" * 80)
        print("ğŸ“‹ åå¾©1: åˆæœŸèª¿æŸ»è¨ˆç”»ã‚’ç«‹æ¡ˆ")
        print("â”€" * 80)
    
    planner_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€åŒ…æ‹¬çš„ã§ä½“ç³»çš„ãªèª¿æŸ»è¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ:
{theme}

è¦ä»¶:
- ãƒ†ãƒ¼ãƒã‚’5-8å€‹ã®ä¸»è¦èª¿æŸ»é ˜åŸŸã«åˆ†è§£ã™ã‚‹
- å„é ˜åŸŸã«ã¤ã„ã¦3-5å€‹ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å®šç¾©ã™ã‚‹
- èª¿æŸ»é ˜åŸŸã®å„ªå…ˆé †ä½ã‚’æ˜ç¢ºã«ã™ã‚‹
- æ®µéšçš„ãªèª¿æŸ»æˆ¦ç•¥ã‚’è¨˜è¿°ã™ã‚‹
- æœŸå¾…ã•ã‚Œã‚‹æˆæœã‚’3-5å€‹å®šç¾©ã™ã‚‹
"""
    
    current_plan = await _run_with_retry(
        planner, planner_prompt, SearchPlanOutput,
        agent_name="Planner", verbose=verbose,
    )
    
    if verbose:
        print("âœ… èª¿æŸ»è¨ˆç”»ãŒç«‹æ¡ˆã•ã‚Œã¾ã—ãŸ")
        print(f"   èª¿æŸ»é ˜åŸŸ: {len(current_plan.research_areas)}")
        print(f"   å„ªå…ˆé ˜åŸŸ: {', '.join(current_plan.priority_order[:3])}...")
        print()
        print("=" * 80)
        print("ğŸ“‹ èª¿æŸ»è¨ˆç”»ã®ç¢ºèª")
        print("=" * 80)
        print(f"\nã€ç›®çš„ã€‘")
        print(f"{current_plan.objective}\n")
        print(f"ã€èª¿æŸ»é ˜åŸŸã€‘ï¼ˆ{len(current_plan.research_areas)}å€‹ï¼‰")
        for i, area in enumerate(current_plan.research_areas, 1):
            keywords = current_plan.search_keywords.get(area, [])
            print(f"  {i}. {area}")
            print(f"     ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords)}")
        print(f"\nã€å„ªå…ˆé †ä½ã€‘")
        for i, area in enumerate(current_plan.priority_order, 1):
            print(f"  {i}. {area}")
        print(f"\nã€èª¿æŸ»æˆ¦ç•¥ã€‘")
        print(f"{current_plan.research_strategy}\n")
        print(f"ã€æœŸå¾…ã•ã‚Œã‚‹æˆæœã€‘")
        for i, outcome in enumerate(current_plan.expected_outcomes, 1):
            print(f"  {i}. {outcome}")
        print("\n" + "=" * 80)
        print("ã“ã®è¨ˆç”»ã§èª¿æŸ»ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        print("èª¿æŸ»è¨ˆç”»ã‚’ä¿®æ­£ã—ãŸã„å ´åˆã¯ã€è¿½åŠ ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        print("ãã®ã¾ã¾ç¶šè¡Œã™ã‚‹å ´åˆã¯ã€Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        print("=" * 80)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
    user_input = input("\nâ¤ ").strip()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿½åŠ æŒ‡ç¤ºã‚’å…¥åŠ›ã—ãŸå ´åˆã€è¨ˆç”»ã‚’ä¿®æ­£
    if user_input:
        if verbose:
            print("\n" + "â”€" * 80)
            print("ğŸ”„ èª¿æŸ»è¨ˆç”»ã‚’ä¿®æ­£ä¸­...")
            print("â”€" * 80)
        
        refinement_prompt = f"""
ä»¥ä¸‹ã®èª¿æŸ»è¨ˆç”»ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è¿½åŠ æŒ‡ç¤ºã‚’åæ˜ ã—ã¦è¨ˆç”»ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®èª¿æŸ»è¨ˆç”»:
- ç›®çš„: {current_plan.objective}
- èª¿æŸ»é ˜åŸŸ: {', '.join(current_plan.research_areas)}
- å„ªå…ˆé †ä½: {', '.join(current_plan.priority_order)}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è¿½åŠ æŒ‡ç¤º:
{user_input}

è¦ä»¶:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‚’é©åˆ‡ã«åæ˜ ã™ã‚‹
- èª¿æŸ»ã®è³ªã¨ç¶²ç¾…æ€§ã‚’ç¶­æŒã¾ãŸã¯å‘ä¸Šã•ã›ã‚‹
- å®Ÿè¡Œå¯èƒ½ã§å…·ä½“çš„ãªè¨ˆç”»ã‚’ç«‹æ¡ˆã™ã‚‹
"""
        
        current_plan = await _run_with_retry(
            planner, refinement_prompt, SearchPlanOutput,
            agent_name="Planner", verbose=verbose,
        )
        
        if verbose:
            print("âœ… èª¿æŸ»è¨ˆç”»ãŒä¿®æ­£ã•ã‚Œã¾ã—ãŸ")
            print(f"   èª¿æŸ»é ˜åŸŸ: {len(current_plan.research_areas)}")
            print(f"   å„ªå…ˆé ˜åŸŸ: {', '.join(current_plan.priority_order[:3])}...")
            print()
    
    # åå¾©2ä»¥é™: èª¿æŸ»å®Ÿè¡Œ â†’ è©•ä¾¡ â†’ ä¿®æ­£ã®ã‚µã‚¤ã‚¯ãƒ«
    evaluations = []
    current_result = None
    # å„åå¾©ã®researcherç”Ÿçµæœã‚’ä¿å­˜ï¼ˆURLã‚’å¤‰æ›´ã›ãšå¾Œã‹ã‚‰æ¤œè¨¼å¯èƒ½ã«ã™ã‚‹ï¼‰
    raw_results: list[dict] = []
    # FCé€šéã—ãŸåå¾©ã®findingsã¨evidenceï¼ˆãƒ¬ãƒãƒ¼ãƒˆã«ä½¿ç”¨ã™ã‚‹ï¼‰
    accepted_findings: list[Finding] = []
    accepted_evidence: list[Evidence] = []
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å±¥æ­´ï¼ˆåå¾©ã‚’ã¾ãŸã„ã§å¼•ãç¶™ãï¼‰
    fact_check_history: list[dict] = []
    
    for iteration in range(1, max_iterations + 1):
        if verbose:
            print("â”€" * 80)
            print(f"ğŸ”¬ åå¾©{iteration}: èª¿æŸ»å®Ÿè¡Œ")
            print("â”€" * 80)
        
        # â”€â”€ å‰å›ã®FCé€šéçµæœã¨é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’researcherã«æ¸¡ã™ â”€â”€
        previous_context = ""
        if accepted_findings:
            previous_context += f"""
ã€å‰å›ã¾ã§ã®FCé€šéç™ºè¦‹äº‹é …ï¼ˆ{len(accepted_findings)}ä»¶ï¼‰ã€‘
ä»¥ä¸‹ã¯å‰å›ã¾ã§ã«ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ãŸç™ºè¦‹äº‹é …ã§ã™ã€‚ã“ã‚Œã‚‰ã¨é‡è¤‡ã—ãªã„æ–°ã—ã„æƒ…å ±ã‚’æ¢ã—ã¦ãã ã•ã„ã€‚
{chr(10).join(f'  - {f.content[:80]}...' for f in accepted_findings[:10])}
"""
        if accepted_evidence:
            previous_context += f"""
ã€å‰å›ã¾ã§ã®FCé€šéæ ¹æ‹ æƒ…å ±ï¼ˆ{len(accepted_evidence)}ä»¶ï¼‰ã€‘
ä»¥ä¸‹ã®URLã¯ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯é€šéæ¸ˆã¿ã§ã™ã€‚æ–°ã—ã„URLã‚’æ¢ã™ã“ã¨ã€‚
{chr(10).join(f'  - {e.url} ({e.title})' for e in accepted_evidence[:8])}
"""
        if fact_check_history:
            latest_fc = fact_check_history[-1]
            previous_context += f"""
ã€âš ï¸ å‰å›ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ â€” é‡è¦ã€‘
- æ¤œè¨¼æ¸ˆã¿: {latest_fc['verified']}ä»¶ / é™¤å¤–: {latest_fc['removed']}ä»¶
- ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {latest_fc['reliability']:.1%}
"""
            if latest_fc.get('removed_reasons'):
                previous_context += "- é™¤å¤–ã•ã‚ŒãŸURL/æƒ…å ±ã®ãƒ‘ã‚¿ãƒ¼ãƒ³:\n"
                for reason in latest_fc['removed_reasons'][:5]:
                    previous_context += f"  âŒ {reason}\n"
                previous_context += """
**ä¸Šè¨˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ¶å¯¾ã«ç¹°ã‚Šè¿”ã•ãªã„ã“ã¨ã€‚**
æ¶ç©ºã®URLã‚’ç”Ÿæˆã—ãŸå ´åˆã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§å†ã³é™¤å¤–ã•ã‚Œã¾ã™ã€‚
WebSearchToolã§å®Ÿéš›ã«å–å¾—ã—ãŸURLã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
"""
        
        # è©•ä¾¡è€…ã‹ã‚‰ã®æ”¹å–„æŒ‡ç¤º
        improvement_instruction = ""
        if evaluations:
            last_eval = evaluations[-1]
            if last_eval.coverage_gaps:
                improvement_instruction += f"""
ã€è©•ä¾¡è€…ã‹ã‚‰ã®æ”¹å–„è¦æ±‚ã€‘
- å‰å›ã®ç·åˆã‚¹ã‚³ã‚¢: {last_eval.overall_quality_score}/60
- ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {last_eval.credibility_score}/10
- ä¸è¶³ã—ã¦ã„ã‚‹è¦³ç‚¹: {', '.join(last_eval.coverage_gaps[:5])}
- æ”¹å–„æˆ¦ç•¥: {last_eval.refinement_strategy or 'ç‰¹ã«ãªã—'}
ä¸Šè¨˜ã®ãƒŒã‚±ãƒ¢ãƒ¬ã‚’é‡ç‚¹çš„ã«èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚
"""
        
        # èª¿æŸ»å®Ÿè¡Œ
        researcher_prompt = f"""
ä»¥ä¸‹ã®èª¿æŸ»è¨ˆç”»ã«å¾“ã£ã¦ã€è©³ç´°ã§ä½“ç³»çš„ãªèª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

ç¾åœ¨ã®åå¾©ç•ªå·: {iteration}

èª¿æŸ»è¨ˆç”»:
- ç›®çš„: {current_plan.objective}
- èª¿æŸ»é ˜åŸŸ: {', '.join(current_plan.research_areas)}
- æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {json.dumps(current_plan.search_keywords, ensure_ascii=False)}
- èª¿æŸ»æˆ¦ç•¥: {current_plan.research_strategy}
{previous_context}{improvement_instruction}
è¦ä»¶:
- è¨ˆç”»ã«å¾“ã£ã¦ã€ä½“ç³»çš„ã«æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹
- 10-15å€‹ã®è©³ç´°ãªç™ºè¦‹äº‹é …ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆå“è³ªé‡è¦–ãƒ»æ•°ã‚ˆã‚Šè³ªï¼‰
- å„ç™ºè¦‹äº‹é …ã«æ ¹æ‹ æƒ…å ±ï¼ˆURLã€å‡ºæ‰€ï¼‰ã‚’è¨˜éŒ²ã™ã‚‹
- é ˜åŸŸé–“ã®ç›¸äº’é–¢é€£æ€§ã‚’ç‰¹å®šã™ã‚‹
- èª¿æŸ»ã®æ·±ã•ã¨å…·ä½“æ€§ã‚’æœ€å¤§åŒ–ã™ã‚‹
- 200-400å­—ã®ç·æ‹¬ã‚’ä½œæˆã™ã‚‹
- å‡ºåŠ›ã«ã¯å¿…ãšthemeã€plan_usedã€iteration_numberã‚’å«ã‚ã‚‹ã“ã¨

ã€æœ€é‡è¦ã€‘å‡ºå…¸URLã«é–¢ã™ã‚‹å³æ ¼ãªãƒ«ãƒ¼ãƒ«:
- evidenceã®URLã¯ã€WebSearchToolã§å®Ÿéš›ã«å–å¾—ã—ãŸæ¤œç´¢çµæœã®URLã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- URLã‚’è‡ªåˆ†ã§æ¨æ¸¬ãƒ»ç”Ÿæˆãƒ»æé€ ã—ã¦ã¯ãªã‚‰ãªã„
- Webæ¤œç´¢ã§è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸæƒ…å ±æºã®URLã‚’ä½œã‚Šå‡ºã—ã¦ã¯ãªã‚‰ãªã„
- ã€Œarxiv.org/abs/2501.12345ã€ã®ã‚ˆã†ãªæ•´ã£ãŸç•ªå·ã®URLã‚’æé€ ã—ãªã„
- URLãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€findingsã®sourceã«ã€ŒWebæ¤œç´¢ã§é–¢é€£æƒ…å ±ã‚’ç¢ºèªã€ç­‰ã¨è¨˜è¼‰ã—ã€
  evidenceã«ã¯å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããŸURLã®ã¿ã‚’å«ã‚ã‚‹
- æ¶ç©ºã®çµ„ç¹”åã€å­¦ä¼šåã€ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åã‚’ä½œã‚Šå‡ºã•ãªã„
"""
        
        current_result = await _run_with_retry(
            researcher, researcher_prompt, ResearchResultOutput,
            agent_name="Researcher", verbose=verbose,
        )
        
        # â”€â”€ researcher ã®ç”Ÿçµæœã‚’ä¿å­˜ï¼ˆURLã‚’ä¸€åˆ‡å¤‰æ›´ã—ãªã„ï¼‰ â”€â”€
        raw_results.append({
            'iteration': iteration,
            'findings': [{'content': f.content, 'source': f.source} for f in current_result.findings],
            'evidence': [{'title': e.title, 'url': e.url, 'summary': e.summary} for e in current_result.evidence],
            'summary': current_result.summary,
        })
        
        if verbose:
            print(f"âœ… èª¿æŸ»ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆåå¾©{iteration}ï¼‰")
            print(f"   ç™ºè¦‹äº‹é …æ•°: {len(current_result.findings)}")
            print(f"   æ ¹æ‹ æƒ…å ±æ•°: {len(current_result.evidence)}")
            print()
        
        # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯: URLã®å®Ÿåœ¨æ€§ã¨å†…å®¹ã®é–¢é€£æ€§ã‚’æ¤œè¨¼
        # evidence/findingsãŒä¸¡æ–¹ç©ºã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        has_evidence = bool(current_result.evidence)
        has_findings = bool(current_result.findings)
        
        if not has_evidence and not has_findings:
            if verbose:
                print("âš ï¸  evidenceãƒ»findingsãŒå…±ã«ç©ºã®ãŸã‚ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            fact_check = None
        else:
            if verbose:
                print("â”€" * 80)
                print(f"ğŸ” åå¾©{iteration}: å‡ºå…¸URLã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯")
                print("â”€" * 80)
            
            fact_checker = create_fact_checker_agent()
            
            evidence_section = "ï¼ˆevidenceãªã—ï¼‰" if not has_evidence else chr(10).join(
                f'- ã‚¿ã‚¤ãƒˆãƒ«: {e.title}, URL: {e.url}, æ¦‚è¦: {e.summary}' for e in current_result.evidence
            )
            findings_section = "ï¼ˆfindingsãªã—ï¼‰" if not has_findings else chr(10).join(
                f'- å†…å®¹: {f.content[:100]}..., å‡ºæ‰€: {f.source}' for f in current_result.findings
            )
            
            fact_check_prompt = f"""
ä»¥ä¸‹ã®èª¿æŸ»çµæœã«å«ã¾ã‚Œã‚‹å‡ºå…¸URLã‚’1ä»¶ãšã¤æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚

å„URLã«ã¤ã„ã¦:
1. Webæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã§URLã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’è©¦ã¿ã‚‹
2. ã‚¿ã‚¤ãƒˆãƒ«ã‚„å†…å®¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§Webæ¤œç´¢ã—ã¦å®Ÿåœ¨ã‚’ç¢ºèª
3. ç„¡åŠ¹ãªURLã®å ´åˆã€åŒã˜å†…å®¹ã®ä»£æ›¿URLã‚’æ¢ã™

ã€æ¤œè¨¼å¯¾è±¡: æ ¹æ‹ æƒ…å ±ï¼ˆevidenceï¼‰ã€‘
{evidence_section}

ã€æ¤œè¨¼å¯¾è±¡: ç™ºè¦‹äº‹é …ï¼ˆfindingsï¼‰ã€‘
{findings_section}

æ¤œè¨¼ã®éš›ã®æ³¨æ„:
- å¿…ãšWebæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å„URLã®å®Ÿåœ¨æ€§ã‚’ç¢ºèªã™ã‚‹ã“ã¨
- arxiv.org/abs/XXXX.XXXXX ã®ã‚ˆã†ãªç•ªå·ãŒæ•´ã„ã™ããŸURLã¯ç‰¹ã«æ³¨æ„
- å®Ÿåœ¨ã—ãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„ãƒ‘ã‚¹ã‚’è¦‹é€ƒã•ãªã„ã“ã¨
- URLãŒç„¡åŠ¹ã§ã‚‚ã€å†…å®¹è‡ªä½“ãŒWebæ¤œç´¢ã§è£ä»˜ã‘ã‚‰ã‚Œã‚‹å ´åˆã¯ä»£æ›¿URLã‚’æç¤º
- å®Œå…¨ã«è£ä»˜ã‘ãŒå–ã‚Œãªã„æƒ…å ±ã¯fabricatedã¨ã—ã¦é™¤å¤–
"""
            
            fact_check = await _run_with_retry(
                fact_checker, fact_check_prompt, FactCheckResultOutput,
                agent_name="FactChecker", verbose=verbose,
            )
        
        if fact_check is not None:
            if verbose:
                print(f"âœ… ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
                print(f"   æ¤œè¨¼æ¸ˆã¿ç™ºè¦‹äº‹é …: {fact_check.total_verified}")
                print(f"   é™¤å¤–ã•ã‚ŒãŸç™ºè¦‹äº‹é …: {fact_check.total_removed}")
                print(f"   ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {fact_check.reliability_score:.1%}")
                print()
            
            # â”€â”€ ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å±¥æ­´ã‚’è¨˜éŒ² â”€â”€
            removed_reasons = []
            for rf in (fact_check.removed_findings or []):
                removed_reasons.append(f"{rf.content[:50]}... â†’ {rf.reason}")
            for re_ in (fact_check.removed_evidences or []):
                removed_reasons.append(f"URL: {re_.original_url} â†’ {re_.reason}")
            
            fact_check_history.append({
                'iteration': iteration,
                'verified': fact_check.total_verified,
                'removed': fact_check.total_removed,
                'reliability': fact_check.reliability_score,
                'removed_reasons': removed_reasons,
                'summary': fact_check.verification_summary,
            })
            
            # â”€â”€ FCçµæœã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ã®æ‰±ã„ â”€â”€
            # URLã¯å¤‰æ›´ã—ãªã„ã€‚FCé€šéåˆ†ã®ã¿researcherã®ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡ºã—ã¦è“„ç©ã€‚
            # FCå¤±æ•—ãƒ‡ãƒ¼ã‚¿ã¯ãƒ¬ãƒãƒ¼ãƒˆã«ä½¿ç”¨ã—ãªã„ï¼ˆã‚¹ã‚³ã‚¢ã‚¼ãƒ­æ‰±ã„ï¼‰ã€‚
            
            # verified_findingsã® content ã‚’ä½¿ã£ã¦ã€å…ƒã®researcher findingsã‹ã‚‰è©²å½“åˆ†ã‚’ç‰¹å®š
            verified_contents = {vf.content[:80] for vf in fact_check.verified_findings}
            verified_urls = set()
            for ve in fact_check.verified_evidences:
                # verified_evidences ã«ã¯original_urlãŒã‚ã‚‹å ´åˆã¯ãã¡ã‚‰ã€ãªã‘ã‚Œã°urlã‚’ä½¿ã†
                original = ve.original_url if ve.original_url else ve.url
                if original:
                    verified_urls.add(original)
                if ve.url:
                    verified_urls.add(ve.url)
            
            # researcherã®ã‚ªãƒªã‚¸ãƒŠãƒ«findingsã‹ã‚‰FCé€šéåˆ†ã‚’æŠ½å‡ºï¼ˆURLã¯å¤‰æ›´ã—ãªã„ï¼‰
            iteration_accepted_findings = []
            for f in current_result.findings:
                if f.content[:80] in verified_contents:
                    iteration_accepted_findings.append(f)
            
            # researcherã®ã‚ªãƒªã‚¸ãƒŠãƒ«evidenceã‹ã‚‰FCé€šéåˆ†ã‚’æŠ½å‡ºï¼ˆURLã¯å¤‰æ›´ã—ãªã„ï¼‰
            iteration_accepted_evidence = []
            for e in current_result.evidence:
                if e.url in verified_urls:
                    iteration_accepted_evidence.append(e)
            
            # accepted ãƒªã‚¹ãƒˆã«è“„ç©ï¼ˆé‡è¤‡æ’é™¤ï¼‰
            existing_contents = {f.content[:80] for f in accepted_findings}
            for f in iteration_accepted_findings:
                if f.content[:80] not in existing_contents:
                    accepted_findings.append(f)
                    existing_contents.add(f.content[:80])
            
            existing_urls = {e.url for e in accepted_evidence}
            for e in iteration_accepted_evidence:
                if e.url and e.url not in existing_urls:
                    accepted_evidence.append(e)
                    existing_urls.add(e.url)
            
            if verbose:
                print(f"   â†’ ã“ã®åå¾©ã§FCé€šéã—ãŸç™ºè¦‹äº‹é …: {len(iteration_accepted_findings)}")
                print(f"   â†’ ã“ã®åå¾©ã§FCé€šéã—ãŸæ ¹æ‹ æƒ…å ±: {len(iteration_accepted_evidence)}")
                print(f"   â†’ è“„ç©ã•ã‚ŒãŸFCé€šéç™ºè¦‹äº‹é …æ•°: {len(accepted_findings)}")
                print(f"   â†’ è“„ç©ã•ã‚ŒãŸFCé€šéæ ¹æ‹ æƒ…å ±æ•°: {len(accepted_evidence)}")
                if fact_check.removed_findings:
                    print(f"   âš ï¸  é™¤å¤–ã•ã‚ŒãŸç™ºè¦‹äº‹é …:")
                    for rf in fact_check.removed_findings[:5]:
                        print(f"      - {rf.content[:60]}... ({rf.reason})")
                print()
        else:
            # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã‚‚å±¥æ­´ã«è¨˜éŒ²
            fact_check_history.append({
                'iteration': iteration,
                'verified': 0,
                'removed': 0,
                'reliability': 0.0,
                'removed_reasons': [],
                'summary': 'ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆevidence/findingsãŒç©ºï¼‰',
            })
        
        # è©•ä¾¡
        if verbose:
            print("â”€" * 80)
            print(f"â­ åå¾©{iteration}: è©•ä¾¡ã¨ä¿®æ­£åˆ¤å®š")
            print("â”€" * 80)
        
        # éå»ã®è©•ä¾¡çµæœã‚’è¦ç´„ï¼ˆåå¾©æ”¹å–„ã®å‚è€ƒæƒ…å ±ï¼‰
        past_eval_summary = ""
        if evaluations:
            past_eval_summary = "\néå»ã®è©•ä¾¡å±¥æ­´:\n"
            for past_eval in evaluations:
                past_eval_summary += f"  åå¾©{past_eval.iteration_number}: ç·åˆ{past_eval.overall_quality_score}/60 "
                past_eval_summary += f"(ç›®çš„:{past_eval.objective_achievement_score} ç¶²ç¾…:{past_eval.coverage_score} "
                past_eval_summary += f"æ·±ã•:{past_eval.depth_insight_score} å®Ÿç”¨:{past_eval.actionability_score} "
                past_eval_summary += f"ä¿¡é ¼:{past_eval.credibility_score} å®šé‡:{past_eval.quantitative_score})\n"
                if past_eval.coverage_gaps:
                    past_eval_summary += f"  â†’ å‰å›ã®ãƒŒã‚±ãƒ¢ãƒ¬: {', '.join(past_eval.coverage_gaps[:3])}\n"
        
        # â”€â”€ ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã‚’è©•ä¾¡è€…ã«æ¸¡ã™ â”€â”€
        fact_check_section = ""
        if fact_check_history:
            latest_fc = fact_check_history[-1]
            fact_check_section = f"""

ã€âš ï¸ ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ â€” ä¿¡é ¼æ€§è©•ä¾¡ã«å¿…ãšåæ˜ ã™ã‚‹ã“ã¨ã€‘
- æ¤œè¨¼æ¸ˆã¿æƒ…å ±: {latest_fc['verified']}ä»¶
- é™¤å¤–ã•ã‚ŒãŸæƒ…å ±ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰: {latest_fc['removed']}ä»¶
- ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚«ãƒ¼ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {latest_fc['reliability']:.1%}
- æ¤œè¨¼ã‚µãƒãƒªãƒ¼: {latest_fc['summary']}
"""
            if latest_fc['removed'] > 0:
                removal_rate = latest_fc['removed'] / max(latest_fc['verified'] + latest_fc['removed'], 1)
                fact_check_section += f"""
**ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡: {removal_rate:.0%}**
ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§{latest_fc['removed']}ä»¶ãŒé™¤å¤–ã•ã‚Œã¦ã„ã¾ã™ã€‚
credibility_score ã¯ã“ã®çµæœã‚’å³æ ¼ã«åæ˜ ã—ã¦ãã ã•ã„:
- é™¤å¤–ç‡ > 30%: credibility_score ã¯ 5 ä»¥ä¸‹ã«ã™ã‚‹ã“ã¨
- é™¤å¤–ç‡ > 20%: credibility_score ã¯ 6 ä»¥ä¸‹ã«ã™ã‚‹ã“ã¨  
- é™¤å¤–ç‡ > 10%: credibility_score ã¯ 7 ä»¥ä¸‹ã«ã™ã‚‹ã“ã¨
- é™¤å¤–ç‡ 0%: credibility_score ã¯ 8 ä»¥ä¸Šå¯èƒ½
"""
            # ç´¯è¨ˆã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å±¥æ­´
            if len(fact_check_history) > 1:
                fact_check_section += "\nãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å±¥æ­´:\n"
                for fc in fact_check_history:
                    fact_check_section += f"  åå¾©{fc['iteration']}: æ¤œè¨¼{fc['verified']}ä»¶ / é™¤å¤–{fc['removed']}ä»¶ (ä¿¡é ¼æ€§: {fc['reliability']:.1%})\n"
        
        evaluator_prompt = f"""
ä»¥ä¸‹ã®èª¿æŸ»çµæœã‚’ã€å½“è©²åˆ†é‡ã®å°‚é–€å®¶ã®ç«‹å ´ã§**æ¥µã‚ã¦å³æ ¼ã«**è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

**é‡è¦**: åˆå›ã®èª¿æŸ»ã¯å¿…ãšæ”¹å–„ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚æœ€åˆã®2å›ã¯ç‰¹ã«æ‰¹åˆ¤çš„ã«è©•ä¾¡ã—ã€
å…·ä½“çš„ãªæ”¹å–„æ¡ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚è¡¨é¢çš„ãªæƒ…å ±åé›†ã§ã¯é«˜å¾—ç‚¹ã‚’ä¸ãˆãªã„ã§ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

èª¿æŸ»è¨ˆç”»ã®ç›®çš„:
{current_plan.objective}

èª¿æŸ»çµæœ:
- ç™ºè¦‹äº‹é …æ•°: {len(current_result.findings)}
- ä¸»è¦ç™ºè¦‹äº‹é …:
{chr(10).join(f'  - {f.content} (å‡ºæ‰€: {f.source})' for f in current_result.findings[:15])}
...ï¼ˆå…¨{len(current_result.findings)}ä»¶ï¼‰

æ ¹æ‹ æƒ…å ±:
{chr(10).join(f'  - [{e.title}]({e.url}): {e.summary}' for e in current_result.evidence[:10])}
...ï¼ˆå…¨{len(current_result.evidence)}ä»¶ï¼‰

ç ”ç©¶ã®æ·±ã•åˆ†æ:
{current_result.research_depth_analysis}

é ˜åŸŸé–“ã®ç›¸äº’é–¢é€£æ€§:
{chr(10).join(f'  - {i}' for i in current_result.interconnections[:5])}

ç·æ‹¬:
{current_result.summary}
{fact_check_section}{past_eval_summary}

## è©•ä¾¡æŒ‡ç¤ºï¼ˆ6è»¸è©•ä¾¡ãƒ»å³æ ¼ç‰ˆï¼‰

ä»¥ä¸‹ã®6è»¸ã§0-10ã®ã‚¹ã‚³ã‚¢ã‚’ã¤ã‘ã¦ãã ã•ã„ã€‚å„è»¸ã§å³æ ¼ã«æ¡ç‚¹ã™ã‚‹ã“ã¨ã€‚

1. **objective_achievement_score** (0-10): ç›®çš„é”æˆåº¦ - èª¿æŸ»ç›®çš„ãŒå®Ÿè³ªçš„ã«æº€ãŸã•ã‚Œã¦ã„ã‚‹ã‹
2. **coverage_score** (0-10): ç¶²ç¾…æ€§ - é‡è¦ãªè¦³ç‚¹ãŒã™ã¹ã¦ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹
3. **depth_insight_score** (0-10): æ·±ã•ãƒ»æ´å¯ŸåŠ› - è¡¨é¢çš„ã§ãªãç‹¬è‡ªã®æ´å¯ŸãŒã‚ã‚‹ã‹
4. **actionability_score** (0-10): å®Ÿç”¨æ€§ - æ„æ€æ±ºå®šã«ä½¿ãˆã‚‹å…·ä½“çš„ç¤ºå”†ãŒã‚ã‚‹ã‹
5. **credibility_score** (0-10): ä¿¡é ¼æ€§ - æ¤œè¨¼å¯èƒ½ãªæ ¹æ‹ ã«åŸºã¥ã„ã¦ã„ã‚‹ã‹ã€‚**ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã‚’å¿…ãšåæ˜ ã™ã‚‹ã“ã¨**
6. **quantitative_score** (0-10): å®šé‡æ€§ - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚„å…·ä½“ä¾‹ãŒååˆ†ã‹

**overall_quality_score** = 6è»¸ã®åˆè¨ˆï¼ˆæœ€å¤§60ç‚¹ï¼‰

## æ”¹å–„åˆ¤å®šåŸºæº–ï¼ˆå³æ ¼ç‰ˆï¼‰

- **should_refine = True** ã«ã™ã‚‹æ¡ä»¶ï¼ˆã„ãšã‚Œã‹1ã¤ã§ã‚‚è©²å½“ã™ã‚Œã°ï¼‰:
  - åå¾©å›æ•°ãŒ3å›æœªæº€ï¼ˆæœ€ä½3å›ã¯èª¿æŸ»ã‚’æ”¹å–„ã™ã‚‹ï¼‰
  - ç·åˆã‚¹ã‚³ã‚¢ < 52ç‚¹ï¼ˆ87%æœªæº€ï¼‰
  - ã„ãšã‚Œã‹ã®è»¸ãŒ7ç‚¹æœªæº€
  - 2ã¤ä»¥ä¸Šã®è»¸ãŒ8ç‚¹æœªæº€
  - objective_achievement_score < 8
  - depth_insight_score < 7
  - credibility_score < 7ï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§é™¤å¤–ãŒå¤šã„å ´åˆï¼‰

- **should_refine = False** ã«ã™ã‚‹æ¡ä»¶ï¼ˆã™ã¹ã¦ã‚’æº€ãŸã™å ´åˆã®ã¿ï¼‰:
  - åå¾©å›æ•°ãŒ3å›ä»¥ä¸Š
  - ç·åˆã‚¹ã‚³ã‚¢ >= 52ç‚¹
  - ã™ã¹ã¦ã®è»¸ãŒ7ç‚¹ä»¥ä¸Š
  - objective_achievement_score >= 8
  - depth_insight_score >= 7
  - credibility_score >= 7

## æ”¹å–„ãŒå¿…è¦ãªå ´åˆ

coverage_gaps ã«å…·ä½“çš„ãªä¸è¶³è¦³ç‚¹ã‚’åˆ—æŒ™ã—ã€
refinement_strategy ã«å„ªå…ˆåº¦ä»˜ãã®å…·ä½“çš„æ”¹å–„è¨ˆç”»ã‚’è¨˜è¿°ã—ã€
refined_plan ã«ä¿®æ­£ã•ã‚ŒãŸèª¿æŸ»è¨ˆç”»ï¼ˆSearchPlanOutputå½¢å¼ï¼‰ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ç‰¹ã«ä»¥ä¸‹ã‚’æ„è­˜ã—ãŸæ”¹å–„ã‚’æ±‚ã‚ã¦ãã ã•ã„ï¼š
- å‰å›ã®è©•ä¾¡ã§æŒ‡æ‘˜ã•ã‚ŒãŸãƒŒã‚±ãƒ¢ãƒ¬ã®è§£æ¶ˆ
- **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ¶ç©ºURLï¼‰ã®å‰Šæ¸›** â€” æ”¹å–„æˆ¦ç•¥ã«å¿…ãšå«ã‚ã‚‹ã“ã¨
- æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãƒ»å…·ä½“çš„äº‹ä¾‹ã®è£œå¼·
- å› æœé–¢ä¿‚ã®åˆ†æã¨ç‹¬è‡ªã®æ´å¯Ÿã®è¿½åŠ 
- å®Ÿè¡Œå¯èƒ½ãªç¤ºå”†ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å…·ä½“åŒ–

## å°‚é–€å®¶ã®è¦³å¯Ÿ

expert_observations ã«ã¯ã€ç‡ç›´ã§æ‰¹åˆ¤çš„ãªè©•ä¾¡ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
ã€Œååˆ†ã€ã€Œé«˜å“è³ªã€ãªã©ã®æŠ½è±¡çš„ãªè³›è¾ã§ã¯ãªãã€
ä½•ãŒä¸è¶³ã—ã¦ã„ã‚‹ã‹ã€ã©ã†æ”¹å–„ã™ã¹ãã‹ã‚’å…·ä½“çš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
**ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§ã®é™¤å¤–ä»¶æ•°ãŒå¤šã„å ´åˆã¯ã€ãã®å•é¡Œã‚’å¿…ãšæŒ‡æ‘˜ã™ã‚‹ã“ã¨ã€‚**

åå¾©æ•°: {iteration}/{max_iterations}
"""
        
        evaluation = await _run_with_retry(
            evaluator, evaluator_prompt, EvaluationOutput,
            agent_name="Evaluator", verbose=verbose,
        )
        evaluation.iteration_number = iteration
        evaluations.append(evaluation)
        
        if verbose:
            print(f"âœ… è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆåå¾©{iteration}ï¼‰")
            print(f"   ç›®çš„é”æˆåº¦: {evaluation.objective_achievement_score}/10")
            print(f"   ç¶²ç¾…æ€§: {evaluation.coverage_score}/10")
            print(f"   æ·±ã•ãƒ»æ´å¯ŸåŠ›: {evaluation.depth_insight_score}/10")
            print(f"   å®Ÿç”¨æ€§: {evaluation.actionability_score}/10")
            print(f"   ä¿¡é ¼æ€§: {evaluation.credibility_score}/10")
            print(f"   å®šé‡æ€§: {evaluation.quantitative_score}/10")
            print(f"   ç·åˆã‚¹ã‚³ã‚¢: {evaluation.overall_quality_score}/60")
            print(f"   ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦: {evaluation.should_refine}")
            print()
        
        # ä¿®æ­£åˆ¤å®š
        if not evaluation.should_refine or iteration >= max_iterations:
            if verbose:
                if evaluation.should_refine and iteration >= max_iterations:
                    print(f"âš ï¸  æœ€å¤§åå¾©å›æ•°ã«é”ã—ã¾ã—ãŸ")
                else:
                    print(f"âœ… èª¿æŸ»å“è³ªãŒååˆ†ã§ã™ã€‚åå¾©ã‚’çµ‚äº†ã—ã¾ã™")
                print()
            break
        
        # ä¿®æ­£è¨ˆç”»ã‚’é©ç”¨
        if evaluation.refined_plan:
            current_plan = evaluation.refined_plan
            if verbose:
                print("â”€" * 80)
                print(f"ğŸ”„ åå¾©{iteration+1}ã«å‘ã‘ã¦èª¿æŸ»è¨ˆç”»ã‚’ä¿®æ­£")
                print("â”€" * 80)
                print(f"ä¿®æ­£å†…å®¹: {evaluation.refinement_strategy}")
                print()
    
    # â”€â”€ æœ€çµ‚çµæœã®æ§‹ç¯‰: FCé€šéãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ â”€â”€
    # accepted_findings/evidence ã«ã¯FCé€šéåˆ†ã®ã¿ãŒè“„ç©ã•ã‚Œã¦ã„ã‚‹ã€‚
    # ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ã“ã®FCé€šéãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    if current_result and accepted_findings:
        current_result.findings = list(accepted_findings)
    elif current_result:
        # FCé€šéãŒ0ä»¶ã®å ´åˆã€findingsã‚’ç©ºã«ã™ã‚‹
        current_result.findings = []
    
    if current_result and accepted_evidence:
        current_result.evidence = list(accepted_evidence)
    elif current_result:
        current_result.evidence = []
    
    if verbose:
        print("=" * 80)
        print("âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"   ç·åå¾©å›æ•°: {len(evaluations)}")
        print(f"   æœ€çµ‚ç·åˆã‚¹ã‚³ã‚¢: {evaluations[-1].overall_quality_score}/60")
        if fact_check_history:
            total_verified = sum(fc['verified'] for fc in fact_check_history)
            total_removed = sum(fc['removed'] for fc in fact_check_history)
            print(f"   ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç´¯è¨ˆ: æ¤œè¨¼{total_verified}ä»¶ / é™¤å¤–{total_removed}ä»¶")
        print(f"   æœ€çµ‚ç™ºè¦‹äº‹é …æ•°ï¼ˆFCé€šéã®ã¿ï¼‰: {len(current_result.findings) if current_result else 0}")
        print(f"   æœ€çµ‚æ ¹æ‹ æƒ…å ±æ•°ï¼ˆFCé€šéã®ã¿ï¼‰: {len(current_result.evidence) if current_result else 0}")
        print("=" * 80)
        print()
    
    return current_plan, current_result, evaluations, fact_check_history, raw_results


async def run_comparison_analysis(
    theme: str,
    simple_result: SimpleSearchOutput,
    agentic_result: ResearchResultOutput,
    verbose: bool = True,
) -> ComparisonReportOutput:
    """
    ç°¡æ˜“æ¤œç´¢ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’æ¯”è¼ƒåˆ†æã™ã‚‹ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºCï¼‰.
    
    Args:
        theme: èª¿æŸ»ãƒ†ãƒ¼ãƒ
        simple_result: ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢çµæœ
        agentic_result: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœ
        verbose: é€²æ—ã‚’è¡¨ç¤ºã™ã‚‹ã‹
    
    Returns:
        ComparisonReportOutput: æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
    """
    if verbose:
        print("=" * 80)
        print("ğŸ“Š æ¯”è¼ƒåˆ†æï¼ˆãƒ•ã‚§ãƒ¼ã‚ºCï¼‰ã‚’å®Ÿè¡Œ")
        print("=" * 80)
        print(f"ãƒ†ãƒ¼ãƒ: {theme}")
        print()
    
    analyzer = create_comparison_analyzer_agent()
    
    comparison_prompt = f"""
ä»¥ä¸‹ã®2ã¤ã®èª¿æŸ»çµæœã‚’ã€å¤šé¢çš„ã«æ¯”è¼ƒåˆ†æã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

ã€ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ¤œç´¢çµæœã€‘
ç™ºè¦‹äº‹é …æ•°: {len(simple_result.findings)}
æ ¹æ‹ æƒ…å ±æ•°: {len(simple_result.evidence)}
ã‚«ãƒãƒ¼é ˜åŸŸ: {', '.join(simple_result.coverage_areas)}
ç·æ‹¬:
{simple_result.summary}

ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœã€‘
ç™ºè¦‹äº‹é …æ•°: {len(agentic_result.findings)}
æ ¹æ‹ æƒ…å ±æ•°: {len(agentic_result.evidence)}
èª¿æŸ»ã®æ·±ã•åˆ†æ:
{agentic_result.research_depth_analysis}
ç·æ‹¬:
{agentic_result.summary}

æ¯”è¼ƒåˆ†æã®è¦ä»¶:
1. ä¸¡çµæœã‚’4ã¤ã®è¦³ç‚¹ï¼ˆç›®çš„é”æˆåº¦ã€è¦³ç‚¹ã®ãƒŒã‚±ãƒ¢ãƒ¬ã€å…·ä½“æ€§ãƒ»æ·±ã•ã€äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰ã§å®šé‡çš„ã«è©•ä¾¡
2. å„è¦³ç‚¹ã§æ”¹å–„ç‡ï¼ˆ%ï¼‰ã‚’è¨ˆç®—
3. ç·åˆã‚¹ã‚³ã‚¢ï¼ˆ0-25ï¼‰ã‚’ç®—å‡º
4. ä¸¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¼·ã¿ãƒ»å¼±ã¿ã‚’è©³ç´°ã«åˆ†æ
5. 4è¦³ç‚¹ã§ã®ç›¸é•ç‚¹ã‚’æ˜ç¢ºã«ã™ã‚‹
6. è²»ç”¨å¯¾åŠ¹æœã‚’åˆ†æã—ã€æ´»ç”¨ã‚·ãƒ¼ãƒ³ã”ã¨ã®æ¨å¥¨ã‚’æç¤º
"""
    
    comparison = await _run_with_retry(
        analyzer, comparison_prompt, ComparisonReportOutput,
        agent_name="ComparisonAnalyzer", verbose=verbose,
    )
    
    if verbose:
        print("âœ… æ¯”è¼ƒåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"   ç°¡æ˜“æ¤œç´¢ã‚¹ã‚³ã‚¢: {comparison.simple_search_total_score}/60")
        print(f"   ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œç´¢ã‚¹ã‚³ã‚¢: {comparison.agentic_search_total_score}/60")
        print(f"   ç›®çš„é”æˆåº¦æ”¹å–„ç‡: {comparison.objective_improvement_rate:+.1f}%")
        print(f"   å…·ä½“æ€§ãƒ»æ·±ã•æ”¹å–„ç‡: {comparison.depth_insight_improvement_rate:+.1f}%")
        print("=" * 80)
        print()
    
    return comparison
